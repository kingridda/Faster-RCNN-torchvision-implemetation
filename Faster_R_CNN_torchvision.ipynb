{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Faster R-CNN torchvision PFA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HwB3ac94EN3"
      },
      "source": [
        "#uplaoding some test images to the environment\n",
        "#https://drive.google.com/file/d/1A9e2tZ-EP7oLH1FU_KRfE7GXTS3-C40y/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1TbzCbx-dQTxG67duFJHxAwq-sEQyPARm/view?usp=sharing\n",
        "#https://drive.google.com/file/d/1pCjy-GjGowyeE9KWe2_QHh2OMrkHnAMD/view?usp=sharing\n",
        "!gdown --id 1pCjy-GjGowyeE9KWe2_QHh2OMrkHnAMD\n",
        "!gdown --id 1TbzCbx-dQTxG67duFJHxAwq-sEQyPARm\n",
        "!gdown --id 1A9e2tZ-EP7oLH1FU_KRfE7GXTS3-C40y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owCU4K-6zt4C"
      },
      "source": [
        "import torchvision #computer vision hub of PyTorch\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torchvision.utils import draw_bounding_boxes\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms.functional as F\n",
        "import numpy as np\n",
        "from torchvision.io import read_image\n",
        "from torchvision.transforms.functional import convert_image_dtype\n",
        "import time\n",
        "\n",
        "#utils\n",
        "def show(imgs):\n",
        "    if not isinstance(imgs, list):\n",
        "        imgs = [imgs]\n",
        "    fix, axs = plt.subplots(ncols=len(imgs), squeeze=False)\n",
        "    for i, img in enumerate(imgs):\n",
        "        img = img.detach()\n",
        "        img = F.to_pil_image(img)\n",
        "        axs[0, i].imshow(np.asarray(img))\n",
        "        axs[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
        "def save_result(imgs, filename):\n",
        "  if not isinstance(imgs, list):\n",
        "        imgs = [imgs]\n",
        "  for i, img in enumerate(imgs):\n",
        "        img = img.detach()\n",
        "        img = F.to_pil_image(img)\n",
        "        img.save(filename+\".jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSwFkFOGtydu"
      },
      "source": [
        "#original torchvision classes names (this model is trained on COCO dataset)\n",
        "COCO_INSTANCE_CATEGORY_NAMES = [\n",
        "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
        "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
        "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
        "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
        "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
        "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
        "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
        "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
        "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pufUi5RS6hxz"
      },
      "source": [
        "#loading the Faster RCNN from torchvision (hub for computer vision models)\n",
        "faster_rcnn_model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuyoEweS57vL"
      },
      "source": [
        "#model layers (NB: the model is not sequential)\n",
        "faster_rcnn_model.named_children"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1Lf3m-I6Y8p"
      },
      "source": [
        "#backbone componenet\n",
        "model.backbone"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA6BaH6o6SYT"
      },
      "source": [
        "#region proposal component\n",
        "model.rpn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx3-Mabs6pR3"
      },
      "source": [
        "#load image (upload your image to the environment and )\n",
        "image_int = read_image('test.jpg')\n",
        "\n",
        "#model in evaluation mode\n",
        "faster_rcnn_model.eval()\n",
        "\n",
        "#prediction\n",
        "batch = convert_image_dtype(image_int, dtype=torch.float)\n",
        "batch = [batch]\n",
        "predictions = faster_rcnn_model(batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZsxGwX0z5tU"
      },
      "source": [
        "#model's raw output \n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drgkR2iFsXDS"
      },
      "source": [
        "#processing model output and drawing results\n",
        "#tune the threshold as you wish\n",
        "score_threshold = .4\n",
        "drawings = draw_bounding_boxes(image_int, boxes=predictions[0]['boxes'][predictions[0]['scores'] > score_threshold ])\n",
        "show(drawings)\n",
        "save_result(drawings, \"result\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m69r-ZoitMEh"
      },
      "source": [
        "#vehicules only\n",
        "score_threshold = .4\n",
        "selected_boxes = predictions[0]['boxes'][(predictions[0]['scores'] > score_threshold) &  ((predictions[0]['labels']  < 11) & (predictions[0]['labels'] > 2) )]\n",
        "\n",
        "drawings = draw_bounding_boxes(image_int, boxes=selected_boxes)\n",
        "show(drawings)\n",
        "save_result(drawings, \"result_vehicules_only\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XJM0wLT9Gh5"
      },
      "source": [
        "#evaluating inference time\n",
        "#make sure colab runtime is on GPU mode\n",
        "\n",
        "input = torch.rand(1,3,600, 600)\n",
        "if torch.cuda.is_available():\n",
        "   print('evaluation is taking place on GPU:')\n",
        "   input=input.to('cuda')\n",
        "   model=faster_rcnn_model.to('cuda')\n",
        "else:\n",
        "   print('evaluation is taking place on CPU:')\n",
        "faster_rcnn_model.eval()\n",
        "faster_rcnn_model(input)\n",
        "T = 0\n",
        "for _ in range(5):\n",
        "    t1 = time.time()\n",
        "    faster_rcnn_model(input)\n",
        "    t2 = time.time()\n",
        "    T += (t2-t1)\n",
        "T /= 5\n",
        "print('Faster RCNN inference time : %f s ===> %f FPS' % (T, 1/T)) \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}